# ì‹¤í—˜ì ì¸ ë°ëª¨ ì„œë¹„ìŠ¤ ì œì•ˆ

ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë°ëª¨ í”„ë¡œì íŠ¸ì— ì¶”ê°€í•˜ë©´ ì¢‹ì„ í˜ì‹ ì ì´ê³  ì‹¤í—˜ì ì¸ ì„œë¹„ìŠ¤ë“¤

---

## ğŸ¤– AI/ML ê¸°ë°˜ ì„œë¹„ìŠ¤

### 1. Visual Search Service (ì´ë¯¸ì§€ ê¸°ë°˜ ì œí’ˆ ê²€ìƒ‰)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, TensorFlow/PyTorch, OpenCV, FastAPI

**ê¸°ëŠ¥:**
- ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ ì œí’ˆ ì°¾ê¸°
- ì´ë¯¸ì§€ ë‚´ ì—¬ëŸ¬ ì œí’ˆ ìë™ ê°ì§€
- ìŠ¤íƒ€ì¼ ê¸°ë°˜ ì¶”ì²œ ("ì´ ìŠ¤íƒ€ì¼ê³¼ ì–´ìš¸ë¦¬ëŠ” ì œí’ˆ")

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# visualsearchservice/visual_search.py
import tensorflow as tf
from PIL import Image
import numpy as np

class VisualSearchService:
    def __init__(self):
        self.model = tf.keras.applications.MobileNetV2(weights='imagenet')
        self.feature_extractor = tf.keras.Model(
            inputs=self.model.input,
            outputs=self.model.layers[-2].output
        )

    def extract_features(self, image):
        """ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ"""
        img = Image.open(image).resize((224, 224))
        img_array = np.array(img) / 255.0
        features = self.feature_extractor.predict(np.expand_dims(img_array, axis=0))
        return features

    def find_similar_products(self, image, top_k=5):
        """ìœ ì‚¬í•œ ì œí’ˆ ì°¾ê¸°"""
        query_features = self.extract_features(image)
        # Vector similarity search (FAISS, Annoy ë“± ì‚¬ìš©)
        similar_products = self.vector_db.search(query_features, k=top_k)
        return similar_products
```

**ë°ëª¨ ê°€ì¹˜:**
- Computer Vision ì‹¤ì „ í™œìš©
- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (Milvus, Pinecone) í†µí•©
- ML ëª¨ë¸ ì„œë¹™ íŒ¨í„´

**ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì—°ë™:**
```
User Upload Image
  â†’ Visual Search Service (íŠ¹ì§• ì¶”ì¶œ)
  â†’ Vector DB (ìœ ì‚¬ë„ ê²€ìƒ‰)
  â†’ Product Catalog (ì œí’ˆ ì •ë³´)
  â†’ Frontend (ê²°ê³¼ í‘œì‹œ)
```

---

### 2. Sentiment Analysis Service (ë¦¬ë·° ê°ì • ë¶„ì„)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, Transformers (BERT), FastAPI

**ê¸°ëŠ¥:**
- ì œí’ˆ ë¦¬ë·° ìë™ ê°ì • ë¶„ì„
- ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¶„ë¥˜ ë° ì ìˆ˜í™”
- ì£¼ìš” í‚¤ì›Œë“œ/í† í”½ ì¶”ì¶œ
- ê°€ì§œ ë¦¬ë·° íƒì§€

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
from transformers import pipeline

class SentimentAnalyzer:
    def __init__(self):
        self.sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model="nlptown/bert-base-multilingual-uncased-sentiment"
        )
        self.keyword_extractor = pipeline("ner")

    def analyze_review(self, review_text):
        """ë¦¬ë·° ê°ì • ë¶„ì„"""
        sentiment = self.sentiment_pipeline(review_text)[0]
        keywords = self.keyword_extractor(review_text)

        return {
            'sentiment': sentiment['label'],
            'confidence': sentiment['score'],
            'keywords': self.extract_key_topics(keywords),
            'fake_score': self.detect_fake_review(review_text)
        }

    def aggregate_product_sentiment(self, product_id):
        """ì œí’ˆ ì „ì²´ ë¦¬ë·° ê°ì • ì§‘ê³„"""
        reviews = self.get_product_reviews(product_id)
        sentiments = [self.analyze_review(r) for r in reviews]

        return {
            'overall_sentiment': self.calculate_weighted_sentiment(sentiments),
            'positive_ratio': len([s for s in sentiments if s['sentiment'] == 'positive']) / len(sentiments),
            'top_keywords': self.get_top_keywords(sentiments),
            'trust_score': self.calculate_trust_score(sentiments)
        }
```

**ë°ëª¨ ê°€ì¹˜:**
- NLP/Transformers ì‹¤ì „ í™œìš©
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (Kafka)
- ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì œí’ˆ ë­í‚¹ì— ë°˜ì˜

---

### 3. Dynamic Pricing Service (AI ê¸°ë°˜ ë™ì  ê°€ê²© ì±…ì •)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, Scikit-learn, XGBoost, Redis

**ê¸°ëŠ¥:**
- ìˆ˜ìš”/ê³µê¸‰ ê¸°ë°˜ ì‹¤ì‹œê°„ ê°€ê²© ì¡°ì •
- ê²½ìŸì‚¬ ê°€ê²© ëª¨ë‹ˆí„°ë§
- ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤ ê°€ê²©
- A/B í…ŒìŠ¤íŠ¸ ê¸°ë°˜ ìµœì  ê°€ê²© íƒìƒ‰

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
import xgboost as xgb
from datetime import datetime

class DynamicPricingService:
    def __init__(self):
        self.pricing_model = self.load_model()
        self.price_cache = Redis()

    def calculate_optimal_price(self, product_id, context):
        """ìµœì  ê°€ê²© ê³„ì‚°"""
        features = self.extract_features(product_id, context)

        # Features:
        # - í˜„ì¬ ì¬ê³ ëŸ‰
        # - ìµœê·¼ íŒë§¤ ì†ë„
        # - ì‹œê°„ëŒ€ (í”¼í¬/ë¹„í”¼í¬)
        # - ê²½ìŸì‚¬ ê°€ê²©
        # - ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ (ì‹ ê·œ/ë‹¨ê³¨, VIP ë“±)
        # - ê³„ì ˆì„±
        # - íŠ¹ë³„ ì´ë²¤íŠ¸ (ë¸”ë™í”„ë¼ì´ë°ì´ ë“±)

        base_price = self.get_base_price(product_id)
        optimal_price = self.pricing_model.predict([features])[0]

        # ê°€ê²© ë³€ë™ ì œí•œ (ë„ˆë¬´ ê¸‰ê²©í•œ ë³€í™” ë°©ì§€)
        min_price = base_price * 0.8
        max_price = base_price * 1.5

        final_price = np.clip(optimal_price, min_price, max_price)

        return {
            'product_id': product_id,
            'base_price': base_price,
            'dynamic_price': final_price,
            'discount_percentage': (base_price - final_price) / base_price * 100,
            'reason': self.explain_pricing(features),
            'expires_at': datetime.now() + timedelta(minutes=15)
        }

    def extract_features(self, product_id, context):
        """ê°€ê²© ì±…ì •ì„ ìœ„í•œ íŠ¹ì§• ì¶”ì¶œ"""
        return {
            'inventory_level': self.get_inventory(product_id),
            'sales_velocity': self.get_recent_sales_rate(product_id),
            'time_of_day': datetime.now().hour,
            'day_of_week': datetime.now().weekday(),
            'competitor_price': self.get_competitor_price(product_id),
            'customer_segment': context.get('customer_segment', 'regular'),
            'cart_value': context.get('cart_total', 0),
            'page_views_24h': self.get_product_views(product_id, hours=24)
        }
```

**ë°ëª¨ ê°€ì¹˜:**
- ML ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì •
- ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
- ê°€ê²© ìµœì í™” ì•Œê³ ë¦¬ì¦˜

---

## ğŸ”„ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„œë¹„ìŠ¤

### 4. Real-time Inventory Sync Service (ì‹¤ì‹œê°„ ì¬ê³  ë™ê¸°í™”)

**ê¸°ìˆ  ìŠ¤íƒ:** Go, Kafka, WebSocket, PostgreSQL

**ê¸°ëŠ¥:**
- ì—¬ëŸ¬ ì°½ê³  ê°„ ì‹¤ì‹œê°„ ì¬ê³  ë™ê¸°í™”
- ì¬ê³  ì„ê³„ê°’ ë„ë‹¬ ì‹œ ìë™ ì•Œë¦¼
- ì¬ê³  ì˜ˆì¸¡ (ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜)
- ì‹¤ì‹œê°„ ì¬ê³  í˜„í™© ëŒ€ì‹œë³´ë“œ

**êµ¬í˜„ ì˜ˆì‹œ:**
```go
// inventorysyncservice/inventory_sync.go
package main

import (
    "context"
    "github.com/segmentio/kafka-go"
    "github.com/gorilla/websocket"
)

type InventorySyncService struct {
    kafkaReader *kafka.Reader
    wsClients   map[string]*websocket.Conn
    inventory   map[string]int
}

func (s *InventorySyncService) StreamInventoryUpdates(ctx context.Context) {
    for {
        msg, err := s.kafkaReader.ReadMessage(ctx)
        if err != nil {
            continue
        }

        var update InventoryUpdate
        json.Unmarshal(msg.Value, &update)

        // ì¬ê³  ì—…ë°ì´íŠ¸
        s.updateInventory(update)

        // ì„ê³„ê°’ ì²´í¬
        if s.isLowStock(update.ProductID) {
            s.sendAlert(update.ProductID)
        }

        // WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        s.broadcastToClients(update)
    }
}

func (s *InventorySyncService) PredictStockout(productID string) time.Time {
    """ì¬ê³  ì†Œì§„ ì‹œì  ì˜ˆì¸¡"""
    salesRate := s.calculateSalesVelocity(productID)
    currentStock := s.inventory[productID]

    daysUntilStockout := float64(currentStock) / salesRate
    return time.Now().Add(time.Duration(daysUntilStockout * 24) * time.Hour)
}

func (s *InventorySyncService) AutoReorder(productID string) {
    """ìë™ ì¬ë°œì£¼"""
    prediction := s.PredictStockout(productID)

    if prediction.Sub(time.Now()).Hours() < 72 { // 3ì¼ ì´ë‚´ ì†Œì§„ ì˜ˆìƒ
        s.createPurchaseOrder(productID)
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- Event-driven architecture
- WebSocket ì‹¤ì‹œê°„ í†µì‹ 
- Kafka ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜

---

### 5. Live Shopping Stream Service (ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤)

**ê¸°ìˆ  ìŠ¤íƒ:** Node.js, WebRTC, Redis, MongoDB

**ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
- ë¼ì´ë¸Œ ì±„íŒ…
- ì‹¤ì‹œê°„ ì œí’ˆ í‘œì‹œ ë° êµ¬ë§¤
- íƒ€ì„ë”œ/í•œì • ìˆ˜ëŸ‰ íŒë§¤
- ì‹œì²­ì ì°¸ì—¬ ê²Œì„/ì´ë²¤íŠ¸

**êµ¬í˜„ ì˜ˆì‹œ:**
```javascript
// livestreamservice/stream_manager.js
class LiveStreamService {
    constructor() {
        this.activeStreams = new Map();
        this.redis = new Redis();
        this.webrtc = new WebRTCManager();
    }

    async startStream(hostId, streamConfig) {
        const streamId = generateStreamId();

        // WebRTC ì—°ê²° ì„¤ì •
        const stream = await this.webrtc.createStream({
            host: hostId,
            quality: streamConfig.quality,
            maxViewers: streamConfig.maxViewers
        });

        // ì‹¤ì‹œê°„ ì±„íŒ…ë°© ìƒì„±
        const chatRoom = await this.createChatRoom(streamId);

        // ì‹¤ì‹œê°„ í†µê³„ ì¶”ì 
        this.trackMetrics(streamId);

        this.activeStreams.set(streamId, {
            stream,
            chatRoom,
            viewers: new Set(),
            products: [],
            startTime: new Date()
        });

        return streamId;
    }

    async addProductToStream(streamId, product) {
        """ìŠ¤íŠ¸ë¦¼ì— ì œí’ˆ ì¶”ê°€"""
        const stream = this.activeStreams.get(streamId);

        stream.products.push(product);

        // ëª¨ë“  ì‹œì²­ìì—ê²Œ ì•Œë¦¼
        this.broadcast(streamId, {
            type: 'PRODUCT_ADDED',
            product: product,
            specialOffer: this.generateLimitedOffer(product)
        });
    }

    async handleInstantPurchase(streamId, userId, productId) {
        """ë¼ì´ë¸Œ ì¤‘ ì¦‰ì‹œ êµ¬ë§¤"""
        const timeLimit = 60; // 60ì´ˆ í•œì •

        const order = await this.createFlashOrder({
            userId,
            productId,
            streamId,
            expiresIn: timeLimit
        });

        // ì‹¤ì‹œê°„ êµ¬ë§¤ ì•Œë¦¼
        this.broadcast(streamId, {
            type: 'SOMEONE_PURCHASED',
            product: productId,
            remainingStock: await this.getStock(productId)
        });

        return order;
    }

    trackMetrics(streamId) {
        """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì¶”ì """
        setInterval(async () => {
            const metrics = {
                viewers: this.activeStreams.get(streamId).viewers.size,
                engagement: await this.calculateEngagement(streamId),
                sales: await this.getStreamSales(streamId),
                chatActivity: await this.getChatActivity(streamId)
            };

            await this.redis.set(`stream:${streamId}:metrics`, metrics);
            this.broadcast(streamId, { type: 'METRICS_UPDATE', metrics });
        }, 5000);
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- WebRTC ì‹¤ì‹œê°„ ë¯¸ë””ì–´
- ëŒ€ê·œëª¨ ë™ì‹œ ì ‘ì† ì²˜ë¦¬
- ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì²˜ë¦¬

---

## ğŸ® ê²Œì´ë¯¸í”¼ì¼€ì´ì…˜ ì„œë¹„ìŠ¤

### 6. Loyalty & Gamification Service (ì¶©ì„±ë„ ë° ê²Œì„í™”)

**ê¸°ìˆ  ìŠ¤íƒ:** Java/Kotlin, Spring Boot, PostgreSQL, Redis

**ê¸°ëŠ¥:**
- í¬ì¸íŠ¸/ë°°ì§€/ë ˆë²¨ ì‹œìŠ¤í…œ
- ì¼ì¼ ë¯¸ì…˜ ë° ë„ì „ê³¼ì œ
- ì¹œêµ¬ ì´ˆëŒ€ ë³´ìƒ
- ë¦¬ë”ë³´ë“œ
- ê°€ìƒ ì•„ë°”íƒ€/ì»¤ìŠ¤í„°ë§ˆì´ì§•
- ìŠ¤í•€ ë£°ë ›, ì¶œì„ ì²´í¬ ë“±

**êµ¬í˜„ ì˜ˆì‹œ:**
```kotlin
// gamificationservice/GamificationService.kt
@Service
class GamificationService {

    data class UserProgress(
        val userId: String,
        val level: Int,
        val xp: Int,
        val points: Int,
        val badges: List<Badge>,
        val streak: Int
    )

    fun awardPoints(userId: String, action: UserAction): PointsReward {
        val points = calculatePoints(action)
        val multiplier = getMultiplier(userId) // ë ˆë²¨, ìŠ¤íŠ¸ë¦­ ë“±ì— ë”°ë¥¸ ë°°ìˆ˜

        val totalPoints = (points * multiplier).toInt()

        updateUserPoints(userId, totalPoints)
        checkForLevelUp(userId)
        checkForBadges(userId, action)

        return PointsReward(
            points = totalPoints,
            reason = action.description,
            multiplier = multiplier,
            newBadges = checkNewBadges(userId)
        )
    }

    fun getDailyMissions(userId: String): List<Mission> {
        val userProfile = getUserProfile(userId)

        return listOf(
            Mission(
                id = "daily_purchase",
                title = "ì²« êµ¬ë§¤í•˜ê¸°",
                description = "ì˜¤ëŠ˜ ì²« ì œí’ˆì„ êµ¬ë§¤í•˜ì„¸ìš”",
                reward = 100,
                progress = userProfile.todayPurchases,
                target = 1
            ),
            Mission(
                id = "review_write",
                title = "ë¦¬ë·° ì‘ì„±í•˜ê¸°",
                description = "êµ¬ë§¤í•œ ì œí’ˆì— ë¦¬ë·°ë¥¼ ë‚¨ê¸°ì„¸ìš”",
                reward = 50,
                progress = userProfile.todayReviews,
                target = 1
            ),
            Mission(
                id = "share_product",
                title = "ì œí’ˆ ê³µìœ í•˜ê¸°",
                description = "ë§ˆìŒì— ë“œëŠ” ì œí’ˆì„ ì¹œêµ¬ì—ê²Œ ê³µìœ í•˜ì„¸ìš”",
                reward = 30,
                progress = userProfile.todayShares,
                target = 3
            )
        )
    }

    fun spinLuckyWheel(userId: String): WheelReward {
        """í–‰ìš´ì˜ ë£°ë ›"""
        if (!canSpin(userId)) {
            throw InsufficientPointsException()
        }

        deductPoints(userId, SPIN_COST)

        val reward = generateWeightedReward(
            rewards = listOf(
                Reward("points", 10, weight = 40),
                Reward("points", 50, weight = 30),
                Reward("points", 100, weight = 20),
                Reward("discount", "10%", weight = 7),
                Reward("discount", "20%", weight = 2),
                Reward("free_shipping", null, weight = 1)
            )
        )

        applyReward(userId, reward)

        return WheelReward(
            type = reward.type,
            value = reward.value,
            description = getRewardDescription(reward)
        )
    }

    fun getLeaderboard(type: LeaderboardType, period: Period): List<LeaderboardEntry> {
        """ë¦¬ë”ë³´ë“œ"""
        return when(type) {
            LeaderboardType.POINTS -> getTopPointsEarners(period)
            LeaderboardType.PURCHASES -> getTopBuyers(period)
            LeaderboardType.REVIEWS -> getTopReviewers(period)
            LeaderboardType.REFERRALS -> getTopReferrers(period)
        }
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- ì‚¬ìš©ì ì°¸ì—¬ ì¦ëŒ€ íŒ¨í„´
- ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì¶”ì 

---

## ğŸŒ ì†Œì…œ/ì»¤ë®¤ë‹ˆí‹° ì„œë¹„ìŠ¤

### 7. Social Shopping Service (ì†Œì…œ ì‡¼í•‘)

**ê¸°ìˆ  ìŠ¤íƒ:** Node.js, GraphQL, Neo4j (ê·¸ë˜í”„ DB), Redis

**ê¸°ëŠ¥:**
- ì¹œêµ¬ íŒ”ë¡œìš°/íŒ”ë¡œì›Œ
- ìœ„ì‹œë¦¬ìŠ¤íŠ¸ ê³µìœ 
- ì œí’ˆ í”¼ë“œ (ì¸ìŠ¤íƒ€ê·¸ë¨ ìŠ¤íƒ€ì¼)
- ê³µë™ êµ¬ë§¤ (ê·¸ë£¹ ë°”ì‰)
- ì†Œì…œ ì¦ëª… ("ì¹œêµ¬ 10ëª…ì´ ì´ ì œí’ˆì„ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤")

**êµ¬í˜„ ì˜ˆì‹œ:**
```javascript
// socialshoppingservice/social_service.js
class SocialShoppingService {
    constructor() {
        this.neo4j = new Neo4jDriver();
        this.redis = new Redis();
    }

    async getFriendActivity(userId, limit = 20) {
        """ì¹œêµ¬ë“¤ì˜ ìµœê·¼ í™œë™"""
        const query = `
            MATCH (user:User {id: $userId})-[:FOLLOWS]->(friend:User)
            MATCH (friend)-[r:PURCHASED|REVIEWED|LIKED]->(product:Product)
            RETURN friend, type(r) as action, product, r.timestamp as timestamp
            ORDER BY timestamp DESC
            LIMIT $limit
        `;

        const activities = await this.neo4j.run(query, { userId, limit });

        return activities.map(a => ({
            friend: a.friend,
            action: a.action,
            product: a.product,
            timestamp: a.timestamp,
            socialProof: this.generateSocialProof(a)
        }));
    }

    async createGroupBuy(userId, productId, targetCount, deadline) {
        """ê³µë™ êµ¬ë§¤ ìƒì„±"""
        const groupBuy = {
            id: generateId(),
            creator: userId,
            product: productId,
            participants: [userId],
            targetCount: targetCount,
            currentCount: 1,
            pricePerPerson: this.calculateGroupPrice(productId, targetCount),
            deadline: deadline,
            status: 'ACTIVE'
        };

        await this.saveGroupBuy(groupBuy);

        // ì¹œêµ¬ë“¤ì—ê²Œ ì•Œë¦¼
        await this.notifyFriends(userId, {
            type: 'GROUP_BUY_INVITATION',
            groupBuy: groupBuy
        });

        return groupBuy;
    }

    async joinGroupBuy(userId, groupBuyId) {
        const groupBuy = await this.getGroupBuy(groupBuyId);

        if (groupBuy.currentCount >= groupBuy.targetCount) {
            throw new Error('Group buy is full');
        }

        groupBuy.participants.push(userId);
        groupBuy.currentCount++;

        if (groupBuy.currentCount === groupBuy.targetCount) {
            await this.completeGroupBuy(groupBuyId);
        }

        return groupBuy;
    }

    async getProductSocialProof(productId, userId) {
        """ì†Œì…œ ì¦ëª… ë°ì´í„°"""
        const query = `
            MATCH (user:User {id: $userId})-[:FOLLOWS]->(friend:User)
            MATCH (friend)-[:PURCHASED]->(product:Product {id: $productId})
            RETURN friend
        `;

        const friends = await this.neo4j.run(query, { userId, productId });

        return {
            friendsPurchased: friends.length,
            friendNames: friends.slice(0, 3).map(f => f.name),
            totalPurchases: await this.getTotalPurchases(productId),
            averageRating: await this.getAverageRating(productId),
            trendingScore: await this.calculateTrendingScore(productId)
        };
    }

    async createProductFeed(userId) {
        """ê°œì¸í™”ëœ ì œí’ˆ í”¼ë“œ"""
        const [
            friendsLiked,
            trending,
            recommendations,
            newArrivals
        ] = await Promise.all([
            this.getFriendsLikedProducts(userId),
            this.getTrendingProducts(),
            this.getPersonalizedRecommendations(userId),
            this.getNewArrivals()
        ]);

        // í”¼ë“œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¯¹ìŠ¤
        const feed = this.mixFeedItems([
            ...friendsLiked.map(p => ({ ...p, source: 'friends' })),
            ...trending.map(p => ({ ...p, source: 'trending' })),
            ...recommendations.map(p => ({ ...p, source: 'for_you' })),
            ...newArrivals.map(p => ({ ...p, source: 'new' }))
        ]);

        return feed;
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ í™œìš©
- ì†Œì…œ ë„¤íŠ¸ì›Œí¬ íŒ¨í„´
- ê°œì¸í™” ì•Œê³ ë¦¬ì¦˜

---

## ğŸ” ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ì„œë¹„ìŠ¤

### 8. Customer Analytics Service (ê³ ê° ë¶„ì„)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, Apache Spark, ClickHouse, Superset

**ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ ì‚¬ìš©ì í–‰ë™ ì¶”ì 
- ì½”í˜¸íŠ¸ ë¶„ì„
- í¼ë„ ë¶„ì„
- RFM (Recency, Frequency, Monetary) ë¶„ì„
- ì´íƒˆ ì˜ˆì¸¡
- ìƒì•  ê°€ì¹˜(LTV) ì˜ˆì¸¡

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# analyticsservice/customer_analytics.py
from pyspark.sql import SparkSession
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

class CustomerAnalyticsService:
    def __init__(self):
        self.spark = SparkSession.builder.appName("CustomerAnalytics").getOrCreate()
        self.churn_model = self.load_churn_model()

    def analyze_user_journey(self, user_id):
        """ì‚¬ìš©ì ì—¬ì • ë¶„ì„"""
        events = self.get_user_events(user_id)

        journey = {
            'acquisition_channel': self.get_acquisition_channel(user_id),
            'first_purchase_time': self.time_to_first_purchase(user_id),
            'conversion_funnel': self.analyze_funnel(events),
            'touchpoints': self.identify_touchpoints(events),
            'drop_off_points': self.find_drop_offs(events)
        }

        return journey

    def segment_customers(self, method='rfm'):
        """ê³ ê° ì„¸ê·¸ë¨¼í…Œì´ì…˜"""
        if method == 'rfm':
            return self.rfm_segmentation()
        elif method == 'behavioral':
            return self.behavioral_clustering()
        elif method == 'value':
            return self.value_based_segmentation()

    def rfm_segmentation(self):
        """RFM ë¶„ì„"""
        query = """
            SELECT
                user_id,
                DATEDIFF(CURRENT_DATE, MAX(order_date)) as recency,
                COUNT(DISTINCT order_id) as frequency,
                SUM(order_total) as monetary
            FROM orders
            GROUP BY user_id
        """

        rfm_df = self.spark.sql(query).toPandas()

        # RFM ì ìˆ˜ ê³„ì‚° (1-5)
        rfm_df['R_Score'] = pd.qcut(rfm_df['recency'], 5, labels=[5,4,3,2,1])
        rfm_df['F_Score'] = pd.qcut(rfm_df['frequency'], 5, labels=[1,2,3,4,5])
        rfm_df['M_Score'] = pd.qcut(rfm_df['monetary'], 5, labels=[1,2,3,4,5])

        # ì„¸ê·¸ë¨¼íŠ¸ ë¼ë²¨ë§
        def assign_segment(row):
            if row['R_Score'] >= 4 and row['F_Score'] >= 4:
                return 'Champions'
            elif row['R_Score'] >= 3 and row['F_Score'] >= 3:
                return 'Loyal Customers'
            elif row['R_Score'] >= 4 and row['F_Score'] <= 2:
                return 'Promising'
            elif row['R_Score'] <= 2 and row['F_Score'] >= 4:
                return 'At Risk'
            elif row['R_Score'] <= 2 and row['F_Score'] <= 2:
                return 'Lost'
            else:
                return 'Need Attention'

        rfm_df['Segment'] = rfm_df.apply(assign_segment, axis=1)

        return rfm_df

    def predict_churn(self, user_id):
        """ì´íƒˆ ì˜ˆì¸¡"""
        features = self.extract_churn_features(user_id)

        churn_probability = self.churn_model.predict_proba([features])[0][1]

        return {
            'user_id': user_id,
            'churn_probability': churn_probability,
            'risk_level': 'HIGH' if churn_probability > 0.7 else 'MEDIUM' if churn_probability > 0.4 else 'LOW',
            'recommended_actions': self.get_retention_actions(churn_probability),
            'key_factors': self.explain_churn_factors(features)
        }

    def calculate_ltv(self, user_id):
        """ê³ ê° ìƒì•  ê°€ì¹˜ ì˜ˆì¸¡"""
        historical_orders = self.get_user_orders(user_id)

        # êµ¬ë§¤ ë¹ˆë„ ì˜ˆì¸¡
        avg_days_between_purchases = self.calculate_purchase_interval(historical_orders)
        estimated_purchases_per_year = 365 / avg_days_between_purchases

        # í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡
        avg_order_value = sum(o['total'] for o in historical_orders) / len(historical_orders)

        # ê³ ê° ìˆ˜ëª… ì˜ˆì¸¡ (ë…„)
        estimated_lifetime = self.predict_customer_lifetime(user_id)

        ltv = estimated_purchases_per_year * avg_order_value * estimated_lifetime

        return {
            'ltv': ltv,
            'avg_order_value': avg_order_value,
            'purchase_frequency': estimated_purchases_per_year,
            'estimated_lifetime_years': estimated_lifetime,
            'confidence': self.calculate_confidence(historical_orders)
        }

    def create_cohort_analysis(self, cohort_type='monthly'):
        """ì½”í˜¸íŠ¸ ë¶„ì„"""
        query = """
            WITH user_cohorts AS (
                SELECT
                    user_id,
                    DATE_TRUNC('month', MIN(order_date)) as cohort_month
                FROM orders
                GROUP BY user_id
            )
            SELECT
                cohort_month,
                DATE_TRUNC('month', order_date) as activity_month,
                COUNT(DISTINCT o.user_id) as active_users,
                SUM(order_total) as revenue
            FROM orders o
            JOIN user_cohorts uc ON o.user_id = uc.user_id
            GROUP BY cohort_month, activity_month
        """

        cohorts = self.spark.sql(query).toPandas()

        # ë¦¬í…ì…˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        retention_matrix = self.build_retention_matrix(cohorts)

        return {
            'retention_matrix': retention_matrix,
            'visualization': self.create_cohort_heatmap(retention_matrix)
        }
```

**ë°ëª¨ ê°€ì¹˜:**
- Big Data ì²˜ë¦¬ (Spark)
- ML ê¸°ë°˜ ì˜ˆì¸¡
- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤

---

## ğŸ” ë¸”ë¡ì²´ì¸/Web3 ì„œë¹„ìŠ¤

### 9. NFT Collectibles Service (NFT ìˆ˜ì§‘í’ˆ)

**ê¸°ìˆ  ìŠ¤íƒ:** Solidity, Hardhat, Ethers.js, IPFS, Node.js

**ê¸°ëŠ¥:**
- í•œì •íŒ ì œí’ˆ NFT ë°œí–‰
- NFT ì†Œìœ ì ì „ìš© í˜œíƒ
- NFT ë§ˆì¼“í”Œë ˆì´ìŠ¤
- ë””ì§€í„¸ ì¸ì¦ì„œ
- ë©”íƒ€ë²„ìŠ¤ ì—°ë™

**êµ¬í˜„ ì˜ˆì‹œ:**
```solidity
// nftservice/contracts/ProductNFT.sol
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC721/ERC721.sol";
import "@openzeppelin/contracts/utils/Counters.sol";

contract ProductNFT is ERC721 {
    using Counters for Counters.Counter;
    Counters.Counter private _tokenIds;

    struct ProductMetadata {
        string productId;
        string name;
        uint256 edition;
        uint256 totalEditions;
        string ipfsHash;
        uint256 purchaseTimestamp;
    }

    mapping(uint256 => ProductMetadata) public nftMetadata;
    mapping(string => uint256[]) public productToTokens;

    event NFTMinted(
        uint256 indexed tokenId,
        address indexed owner,
        string productId,
        uint256 edition
    );

    constructor() ERC721("LimitedEditionProduct", "LEP") {}

    function mintProductNFT(
        address buyer,
        string memory productId,
        string memory name,
        uint256 edition,
        uint256 totalEditions,
        string memory ipfsHash
    ) public returns (uint256) {
        _tokenIds.increment();
        uint256 newTokenId = _tokenIds.current();

        _safeMint(buyer, newTokenId);

        nftMetadata[newTokenId] = ProductMetadata({
            productId: productId,
            name: name,
            edition: edition,
            totalEditions: totalEditions,
            ipfsHash: ipfsHash,
            purchaseTimestamp: block.timestamp
        });

        productToTokens[productId].push(newTokenId);

        emit NFTMinted(newTokenId, buyer, productId, edition);

        return newTokenId;
    }

    function getOwnerBenefits(uint256 tokenId) public view returns (string[] memory) {
        require(_exists(tokenId), "Token does not exist");

        ProductMetadata memory metadata = nftMetadata[tokenId];
        string[] memory benefits = new string[](3);

        benefits[0] = "Lifetime 10% discount on all purchases";
        benefits[1] = "Early access to new product launches";
        benefits[2] = "Exclusive NFT holder events";

        // ì—ë””ì…˜ ë²ˆí˜¸ê°€ ì‘ì„ìˆ˜ë¡ ë” ë§ì€ í˜œíƒ
        if (metadata.edition <= 10) {
            // benefits.push("VIP customer service");
        }

        return benefits;
    }

    function verifyAuthenticity(uint256 tokenId) public view returns (bool) {
        return _exists(tokenId);
    }
}
```

```javascript
// nftservice/nft_service.js
const { ethers } = require('ethers');
const { create } = require('ipfs-http-client');

class NFTService {
    constructor() {
        this.provider = new ethers.providers.JsonRpcProvider(process.env.RPC_URL);
        this.contract = new ethers.Contract(CONTRACT_ADDRESS, ABI, this.provider);
        this.ipfs = create({ host: 'ipfs.infura.io', port: 5001, protocol: 'https' });
    }

    async createLimitedEditionNFT(productId, buyer, edition, totalEditions) {
        """í•œì •íŒ ì œí’ˆ NFT ë°œí–‰"""

        // ë©”íƒ€ë°ì´í„°ë¥¼ IPFSì— ì—…ë¡œë“œ
        const metadata = {
            name: `Limited Edition ${productId} #${edition}`,
            description: `This is ${edition} of ${totalEditions} limited edition`,
            image: await this.uploadImageToIPFS(productId),
            attributes: [
                { trait_type: "Edition", value: edition },
                { trait_type: "Total Supply", value: totalEditions },
                { trait_type: "Product ID", value: productId },
                { trait_type: "Rarity", value: this.calculateRarity(edition, totalEditions) }
            ]
        };

        const ipfsHash = await this.uploadMetadataToIPFS(metadata);

        // NFT ë°œí–‰
        const tx = await this.contract.mintProductNFT(
            buyer,
            productId,
            metadata.name,
            edition,
            totalEditions,
            ipfsHash
        );

        await tx.wait();

        return {
            tokenId: await this.getLatestTokenId(),
            ipfsUrl: `https://ipfs.io/ipfs/${ipfsHash}`,
            openseaUrl: this.getOpenSeaUrl(tokenId)
        };
    }

    async getOwnerPerks(walletAddress) {
        """NFT ì†Œìœ ì í˜œíƒ ì¡°íšŒ"""
        const tokens = await this.contract.tokensOfOwner(walletAddress);

        const perks = {
            discountRate: 0,
            earlyAccess: false,
            exclusiveEvents: false,
            totalNFTs: tokens.length
        };

        if (tokens.length > 0) {
            perks.discountRate = 10; // ê¸°ë³¸ 10%
            perks.earlyAccess = true;
        }

        if (tokens.length >= 5) {
            perks.discountRate = 20; // 5ê°œ ì´ìƒ ì†Œìœ  ì‹œ 20%
            perks.exclusiveEvents = true;
        }

        return perks;
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- ë¸”ë¡ì²´ì¸ í†µí•©
- ìŠ¤ë§ˆíŠ¸ ì»¨íŠ¸ë™íŠ¸
- Web3 ì¸ì¦
- IPFS ë¶„ì‚° ìŠ¤í† ë¦¬ì§€

---

## ğŸ¯ IoT/ì—£ì§€ ì„œë¹„ìŠ¤

### 10. Smart Mirror Service (ìŠ¤ë§ˆíŠ¸ ë¯¸ëŸ¬ ê°€ìƒ í”¼íŒ…)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, OpenCV, MediaPipe, TensorFlow, WebSocket

**ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ AR ê°€ìƒ í”¼íŒ…
- ì–¼êµ´/ì‹ ì²´ ì¸ì‹
- ì˜·/ì•¡ì„¸ì„œë¦¬ ì˜¤ë²„ë ˆì´
- ì‚¬ì´ì¦ˆ ì¶”ì²œ
- ìŠ¤íƒ€ì¼ ì¡°í•© ì œì•ˆ

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# smartmirrorservice/virtual_fitting.py
import cv2
import mediapipe as mp
import numpy as np

class VirtualFittingService:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.mp_face = mp.solutions.face_mesh
        self.pose = self.mp_pose.Pose()
        self.face_mesh = self.mp_face.FaceMesh()

    def process_frame(self, frame, product_type, product_image):
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ê°€ìƒ í”¼íŒ…"""
        results_pose = self.pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        results_face = self.face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        if product_type == 'clothing':
            return self.overlay_clothing(frame, results_pose, product_image)
        elif product_type == 'glasses':
            return self.overlay_glasses(frame, results_face, product_image)
        elif product_type == 'hat':
            return self.overlay_hat(frame, results_face, product_image)

        return frame

    def overlay_glasses(self, frame, face_results, glasses_image):
        """ì•ˆê²½ ì˜¤ë²„ë ˆì´"""
        if not face_results.multi_face_landmarks:
            return frame

        landmarks = face_results.multi_face_landmarks[0]

        # ì–¼êµ´ ëœë“œë§ˆí¬ì—ì„œ ëˆˆ ìœ„ì¹˜ ì¶”ì¶œ
        left_eye = landmarks.landmark[33]  # ì™¼ìª½ ëˆˆ
        right_eye = landmarks.landmark[263]  # ì˜¤ë¥¸ìª½ ëˆˆ

        # ì•ˆê²½ í¬ê¸° ë° ê°ë„ ê³„ì‚°
        eye_distance = np.linalg.norm([
            left_eye.x - right_eye.x,
            left_eye.y - right_eye.y
        ])

        # ì•ˆê²½ ì´ë¯¸ì§€ ë³€í™˜
        glasses_width = int(eye_distance * frame.shape[1] * 2.5)
        glasses_resized = cv2.resize(glasses_image, (glasses_width, glasses_width // 3))

        # ê°ë„ ì¡°ì •
        angle = np.degrees(np.arctan2(right_eye.y - left_eye.y, right_eye.x - left_eye.x))
        glasses_rotated = self.rotate_image(glasses_resized, angle)

        # ì˜¤ë²„ë ˆì´
        overlay_frame = self.overlay_image(frame, glasses_rotated, left_eye, right_eye)

        return overlay_frame

    def measure_body_dimensions(self, pose_results, user_height_cm):
        """ì‹ ì²´ ì¹˜ìˆ˜ ì¸¡ì •"""
        if not pose_results.pose_landmarks:
            return None

        landmarks = pose_results.pose_landmarks.landmark

        # ì–´ê¹¨ ë„ˆë¹„
        left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
        right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
        shoulder_width_px = np.linalg.norm([
            left_shoulder.x - right_shoulder.x,
            left_shoulder.y - right_shoulder.y
        ])

        # í”½ì…€ì„ ì‹¤ì œ cmë¡œ ë³€í™˜ (ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ ê¸°ì¤€)
        pixel_to_cm = user_height_cm / self.calculate_body_height_px(landmarks)

        measurements = {
            'shoulder_width': shoulder_width_px * pixel_to_cm,
            'chest_width': self.estimate_chest_width(landmarks) * pixel_to_cm,
            'waist_width': self.estimate_waist_width(landmarks) * pixel_to_cm,
            'hip_width': self.estimate_hip_width(landmarks) * pixel_to_cm,
        }

        return measurements

    def recommend_size(self, measurements, product_id):
        """ì‚¬ì´ì¦ˆ ì¶”ì²œ"""
        product_sizing = self.get_product_sizing(product_id)

        # ê° ì‚¬ì´ì¦ˆì™€ì˜ ì°¨ì´ ê³„ì‚°
        size_scores = {}
        for size, size_measurements in product_sizing.items():
            score = 0
            for key in measurements:
                if key in size_measurements:
                    diff = abs(measurements[key] - size_measurements[key])
                    score += diff
            size_scores[size] = score

        # ê°€ì¥ ì í•©í•œ ì‚¬ì´ì¦ˆ
        recommended_size = min(size_scores, key=size_scores.get)

        return {
            'recommended_size': recommended_size,
            'fit_score': 100 - (size_scores[recommended_size] / 10),  # 0-100 ì ìˆ˜
            'alternative_sizes': self.get_alternative_sizes(size_scores, recommended_size)
        }
```

**ë°ëª¨ ê°€ì¹˜:**
- Computer Vision ì‹¤ì „ í™œìš©
- AR ê¸°ìˆ 
- ì‹¤ì‹œê°„ ì²˜ë¦¬
- IoT ë””ë°”ì´ìŠ¤ í†µí•©

---

## ğŸ¤ í˜‘ì—… ì„œë¹„ìŠ¤

### 11. Collaborative Shopping Service (í˜‘ì—… ì‡¼í•‘)

**ê¸°ìˆ  ìŠ¤íƒ:** Node.js, Socket.io, WebRTC, React

**ê¸°ëŠ¥:**
- í™”ë©´ ê³µìœ  ì‡¼í•‘
- ìŒì„±/ë¹„ë””ì˜¤ ì±„íŒ…
- ê³µë™ ì¥ë°”êµ¬ë‹ˆ
- ì‹¤ì‹œê°„ íˆ¬í‘œ
- í•¨ê»˜ ê²°ì œí•˜ê¸°

**êµ¬í˜„ ì˜ˆì‹œ:**
```javascript
// collaborativeshoppingservice/collaborative_session.js
class CollaborativeShoppingSession {
    constructor(sessionId) {
        this.sessionId = sessionId;
        this.participants = new Map();
        this.sharedCart = [];
        this.currentProduct = null;
        this.votes = new Map();
    }

    addParticipant(userId, socket) {
        """ì°¸ê°€ì ì¶”ê°€"""
        this.participants.set(userId, {
            socket: socket,
            cursor: { x: 0, y: 0 },
            status: 'active',
            role: this.participants.size === 0 ? 'host' : 'guest'
        });

        // ëª¨ë“  ì°¸ê°€ìì—ê²Œ ì•Œë¦¼
        this.broadcast('PARTICIPANT_JOINED', {
            userId: userId,
            totalParticipants: this.participants.size
        });

        // ìƒˆ ì°¸ê°€ìì—ê²Œ í˜„ì¬ ìƒíƒœ ë™ê¸°í™”
        socket.emit('SESSION_STATE', {
            cart: this.sharedCart,
            currentProduct: this.currentProduct,
            participants: Array.from(this.participants.keys())
        });
    }

    syncCursor(userId, position) {
        """ì»¤ì„œ ìœ„ì¹˜ ë™ê¸°í™”"""
        const participant = this.participants.get(userId);
        if (participant) {
            participant.cursor = position;

            // ë‹¤ë¥¸ ì°¸ê°€ìë“¤ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            this.broadcast('CURSOR_MOVE', {
                userId: userId,
                position: position
            }, userId);
        }
    }

    addToSharedCart(userId, product) {
        """ê³µë™ ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€"""
        this.sharedCart.push({
            ...product,
            addedBy: userId,
            timestamp: new Date()
        });

        this.broadcast('CART_UPDATED', {
            cart: this.sharedCart,
            addedBy: userId,
            product: product
        });
    }

    startProductVote(userId, product) {
        """ì œí’ˆ íˆ¬í‘œ ì‹œì‘"""
        this.votes.clear();
        this.currentProduct = product;

        this.broadcast('VOTE_STARTED', {
            product: product,
            initiatedBy: userId,
            deadline: Date.now() + 60000 // 1ë¶„
        });

        // 1ë¶„ í›„ ìë™ ì§‘ê³„
        setTimeout(() => {
            this.tallyVotes();
        }, 60000);
    }

    castVote(userId, vote) {
        """íˆ¬í‘œí•˜ê¸°"""
        this.votes.set(userId, vote); // 'yes', 'no', 'maybe'

        this.broadcast('VOTE_CAST', {
            userId: userId,
            totalVotes: this.votes.size,
            requiredVotes: this.participants.size
        });

        // ëª¨ë‘ íˆ¬í‘œí–ˆìœ¼ë©´ ì¦‰ì‹œ ì§‘ê³„
        if (this.votes.size === this.participants.size) {
            this.tallyVotes();
        }
    }

    tallyVotes() {
        """íˆ¬í‘œ ì§‘ê³„"""
        const results = {
            yes: 0,
            no: 0,
            maybe: 0
        };

        this.votes.forEach(vote => {
            results[vote]++;
        });

        const decision = results.yes > results.no ? 'approved' : 'rejected';

        this.broadcast('VOTE_COMPLETE', {
            results: results,
            decision: decision,
            product: this.currentProduct
        });

        if (decision === 'approved') {
            this.addToSharedCart('group', this.currentProduct);
        }

        this.votes.clear();
        this.currentProduct = null;
    }

    splitPayment() {
        """ê²°ì œ ë¶„í• """
        const total = this.sharedCart.reduce((sum, item) => sum + item.price, 0);
        const perPerson = total / this.participants.size;

        const splits = [];
        this.participants.forEach((participant, userId) => {
            splits.push({
                userId: userId,
                amount: perPerson,
                items: this.sharedCart.map(item => ({
                    ...item,
                    splitPrice: item.price / this.participants.size
                }))
            });
        });

        this.broadcast('PAYMENT_SPLIT', {
            total: total,
            perPerson: perPerson,
            splits: splits
        });

        return splits;
    }

    broadcast(event, data, excludeUserId = null) {
        """ëª¨ë“  ì°¸ê°€ìì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        this.participants.forEach((participant, userId) => {
            if (userId !== excludeUserId) {
                participant.socket.emit(event, data);
            }
        });
    }
}

// WebSocket ì„œë²„
io.on('connection', (socket) => {
    socket.on('JOIN_SESSION', ({ sessionId, userId }) => {
        const session = getOrCreateSession(sessionId);
        session.addParticipant(userId, socket);
    });

    socket.on('CURSOR_MOVE', ({ sessionId, userId, position }) => {
        const session = sessions.get(sessionId);
        session?.syncCursor(userId, position);
    });

    socket.on('ADD_TO_CART', ({ sessionId, userId, product }) => {
        const session = sessions.get(sessionId);
        session?.addToSharedCart(userId, product);
    });

    socket.on('START_VOTE', ({ sessionId, userId, product }) => {
        const session = sessions.get(sessionId);
        session?.startProductVote(userId, product);
    });

    socket.on('CAST_VOTE', ({ sessionId, userId, vote }) => {
        const session = sessions.get(sessionId);
        session?.castVote(userId, vote);
    });
});
```

**ë°ëª¨ ê°€ì¹˜:**
- ì‹¤ì‹œê°„ í˜‘ì—… íŒ¨í„´
- WebSocket/WebRTC
- ë™ì‹œì„± ì œì–´

---

## ğŸ“± ëª¨ë°”ì¼ ìš°ì„  ì„œë¹„ìŠ¤

### 12. Progressive Web App Service (PWA ìµœì í™”)

**ê¸°ìˆ  ìŠ¤íƒ:** Service Workers, IndexedDB, Web Push API

**ê¸°ëŠ¥:**
- ì˜¤í”„ë¼ì¸ ëª¨ë“œ
- ë°±ê·¸ë¼ìš´ë“œ ë™ê¸°í™”
- í‘¸ì‹œ ì•Œë¦¼
- ì•± ì„¤ì¹˜ í”„ë¡¬í”„íŠ¸
- ë°ì´í„° ì ˆì•½ ëª¨ë“œ

**êµ¬í˜„ ì˜ˆì‹œ:**
```javascript
// pwaservice/service-worker.js
const CACHE_VERSION = 'v1';
const CACHE_STATIC = `static-${CACHE_VERSION}`;
const CACHE_DYNAMIC = `dynamic-${CACHE_VERSION}`;
const CACHE_PRODUCTS = `products-${CACHE_VERSION}`;

// ì„¤ì¹˜ ì‹œ ì •ì  ìì‚° ìºì‹±
self.addEventListener('install', (event) => {
    event.waitUntil(
        caches.open(CACHE_STATIC).then((cache) => {
            return cache.addAll([
                '/',
                '/css/main.css',
                '/js/app.js',
                '/images/logo.png',
                '/offline.html'
            ]);
        })
    );
});

// ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ê°€ë¡œì±„ê¸°
self.addEventListener('fetch', (event) => {
    const { request } = event;

    // API ìš”ì²­ ì²˜ë¦¬
    if (request.url.includes('/api/')) {
        event.respondWith(networkFirstStrategy(request));
    }
    // ì œí’ˆ ì´ë¯¸ì§€ ì²˜ë¦¬
    else if (request.url.includes('/products/')) {
        event.respondWith(cacheFirstStrategy(request));
    }
    // ì •ì  ìì‚° ì²˜ë¦¬
    else {
        event.respondWith(staleWhileRevalidateStrategy(request));
    }
});

// Network First ì „ëµ (APIìš©)
async function networkFirstStrategy(request) {
    try {
        const networkResponse = await fetch(request);
        const cache = await caches.open(CACHE_DYNAMIC);
        cache.put(request, networkResponse.clone());
        return networkResponse;
    } catch (error) {
        const cachedResponse = await caches.match(request);
        return cachedResponse || caches.match('/offline.html');
    }
}

// Cache First ì „ëµ (ì´ë¯¸ì§€ìš©)
async function cacheFirstStrategy(request) {
    const cachedResponse = await caches.match(request);
    if (cachedResponse) {
        return cachedResponse;
    }

    try {
        const networkResponse = await fetch(request);
        const cache = await caches.open(CACHE_PRODUCTS);
        cache.put(request, networkResponse.clone());
        return networkResponse;
    } catch (error) {
        return caches.match('/images/placeholder.png');
    }
}

// Stale While Revalidate ì „ëµ
async function staleWhileRevalidateStrategy(request) {
    const cachedResponse = await caches.match(request);

    const fetchPromise = fetch(request).then((networkResponse) => {
        const cache = caches.open(CACHE_STATIC);
        cache.then((c) => c.put(request, networkResponse.clone()));
        return networkResponse;
    });

    return cachedResponse || fetchPromise;
}

// ë°±ê·¸ë¼ìš´ë“œ ë™ê¸°í™”
self.addEventListener('sync', (event) => {
    if (event.tag === 'sync-cart') {
        event.waitUntil(syncCart());
    } else if (event.tag === 'sync-orders') {
        event.waitUntil(syncOrders());
    }
});

async function syncCart() {
    """ì˜¤í”„ë¼ì¸ ì¤‘ ì¶”ê°€í•œ ì¥ë°”êµ¬ë‹ˆ ë™ê¸°í™”"""
    const db = await openIndexedDB();
    const pendingItems = await db.getAll('pendingCartItems');

    for (const item of pendingItems) {
        try {
            await fetch('/api/cart', {
                method: 'POST',
                body: JSON.stringify(item),
                headers: { 'Content-Type': 'application/json' }
            });
            await db.delete('pendingCartItems', item.id);
        } catch (error) {
            console.error('Failed to sync cart item:', error);
        }
    }
}

// í‘¸ì‹œ ì•Œë¦¼
self.addEventListener('push', (event) => {
    const data = event.data.json();

    const options = {
        body: data.body,
        icon: '/images/icon.png',
        badge: '/images/badge.png',
        vibrate: [200, 100, 200],
        data: {
            url: data.url
        },
        actions: [
            { action: 'view', title: 'ë³´ê¸°' },
            { action: 'dismiss', title: 'ë‹«ê¸°' }
        ]
    };

    event.waitUntil(
        self.registration.showNotification(data.title, options)
    );
});

// ì•Œë¦¼ í´ë¦­ ì²˜ë¦¬
self.addEventListener('notificationclick', (event) => {
    event.notification.close();

    if (event.action === 'view') {
        event.waitUntil(
            clients.openWindow(event.notification.data.url)
        );
    }
});
```

```javascript
// pwaservice/offline_manager.js
class OfflineManager {
    constructor() {
        this.db = null;
        this.initDB();
    }

    async initDB() {
        """IndexedDB ì´ˆê¸°í™”"""
        this.db = await openDB('OfflineStore', 1, {
            upgrade(db) {
                db.createObjectStore('pendingCartItems', { keyPath: 'id', autoIncrement: true });
                db.createObjectStore('cachedProducts', { keyPath: 'id' });
                db.createObjectStore('userPreferences', { keyPath: 'key' });
            }
        });
    }

    async addToOfflineCart(product) {
        """ì˜¤í”„ë¼ì¸ ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€"""
        await this.db.add('pendingCartItems', {
            ...product,
            addedAt: new Date(),
            synced: false
        });

        // ì˜¨ë¼ì¸ì´ ë˜ë©´ ë™ê¸°í™”
        if ('sync' in self.registration) {
            await self.registration.sync.register('sync-cart');
        }
    }

    async getOfflineCart() {
        """ì˜¤í”„ë¼ì¸ ì¥ë°”êµ¬ë‹ˆ ì¡°íšŒ"""
        return await this.db.getAll('pendingCartItems');
    }

    async cacheProduct(product) {
        """ì œí’ˆ ì •ë³´ ìºì‹±"""
        await this.db.put('cachedProducts', product);
    }

    async getCachedProduct(productId) {
        """ìºì‹œëœ ì œí’ˆ ì¡°íšŒ"""
        return await this.db.get('cachedProducts', productId);
    }
}
```

**ë°ëª¨ ê°€ì¹˜:**
- PWA ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
- ì˜¤í”„ë¼ì¸ ìš°ì„  ì „ëµ
- ëª¨ë°”ì¼ ìµœì í™”

---

## ğŸ¨ ê°œì¸í™” ì„œë¹„ìŠ¤

### 13. Hyper-Personalization Service (ì´ˆê°œì¸í™”)

**ê¸°ìˆ  ìŠ¤íƒ:** Python, TensorFlow, Redis, Kafka

**ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ ê°œì¸í™” í™ˆí˜ì´ì§€
- ë™ì  ì»¨í…ì¸  ìƒì„±
- ê°œì¸ë³„ ê°€ê²©/í”„ë¡œëª¨ì…˜
- ë§ì¶¤í˜• ì´ë©”ì¼
- ì˜ˆì¸¡ ê²€ìƒ‰

**êµ¬í˜„ ì˜ˆì‹œ:**
```python
# personalizationservice/hyper_personalization.py
class HyperPersonalizationEngine:
    def __init__(self):
        self.user_profile_model = self.load_model('user_profiling')
        self.content_ranker = self.load_model('content_ranking')
        self.redis = Redis()

    def generate_personalized_homepage(self, user_id, context):
        """ì´ˆê°œì¸í™” í™ˆí˜ì´ì§€ ìƒì„±"""
        # ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ
        user_profile = self.get_user_profile(user_id)

        # ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸
        current_context = {
            'time_of_day': context.get('hour'),
            'device': context.get('device'),
            'location': context.get('location'),
            'weather': self.get_weather(context.get('location')),
            'recent_behavior': self.get_recent_behavior(user_id, hours=24)
        }

        # í™ˆí˜ì´ì§€ ì„¹ì…˜ ìƒì„±
        sections = []

        # 1. íˆì–´ë¡œ ë°°ë„ˆ (ìµœê³  ìš°ì„ ìˆœìœ„)
        hero_banner = self.select_hero_banner(user_profile, current_context)
        sections.append(hero_banner)

        # 2. ë§ì¶¤ ì¶”ì²œ ("ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ")
        recommendations = self.get_personalized_recommendations(
            user_id,
            context=current_context,
            count=12
        )
        sections.append({
            'type': 'product_grid',
            'title': self.generate_title(user_profile),  # "ì˜¤ëŠ˜ì˜ ì¶”ì²œ" vs "ì·¨í–¥ì €ê²© ì•„ì´í…œ"
            'products': recommendations
        })

        # 3. ì‹œê°„ ê¸°ë°˜ ì»¨í…ì¸ 
        if current_context['time_of_day'] < 12:
            sections.append(self.get_morning_deals())
        elif current_context['time_of_day'] < 18:
            sections.append(self.get_lunch_specials())
        else:
            sections.append(self.get_evening_picks())

        # 4. ë‚ ì”¨ ê¸°ë°˜ ì œì•ˆ
        if current_context['weather']['temp'] < 10:
            sections.append(self.get_cold_weather_products())
        elif current_context['weather']['condition'] == 'rainy':
            sections.append(self.get_rainy_day_products())

        # 5. ì¬ë°©ë¬¸ ìœ ë„
        abandoned_items = self.get_abandoned_cart(user_id)
        if abandoned_items:
            sections.append({
                'type': 'reminder',
                'title': 'ì¥ë°”êµ¬ë‹ˆì— ë‚¨ê²¨ë‘ì‹  ìƒí’ˆì´ ìˆì–´ìš”',
                'products': abandoned_items,
                'special_offer': self.generate_incentive(user_profile)  # ì¿ í° ë“±
            })

        # 6. ì†Œì…œ ì¦ëª…
        trending_among_similar = self.get_trending_in_segment(user_profile['segment'])
        sections.append({
            'type': 'social_proof',
            'title': 'ë¹„ìŠ·í•œ ì·¨í–¥ì„ ê°€ì§„ ë¶„ë“¤ì´ êµ¬ë§¤í•œ ìƒí’ˆ',
            'products': trending_among_similar
        })

        return {
            'user_id': user_id,
            'generated_at': datetime.now(),
            'sections': sections,
            'ab_tests': self.get_active_ab_tests(user_id)
        }

    def predictive_search(self, user_id, partial_query):
        """ì˜ˆì¸¡ ê²€ìƒ‰"""
        user_history = self.get_search_history(user_id)
        popular_searches = self.get_popular_searches()

        # ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì˜ˆì¸¡
        user_predictions = self.predict_from_history(partial_query, user_history)

        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡
        context_predictions = self.predict_from_context(partial_query, {
            'season': self.get_current_season(),
            'trending': popular_searches,
            'user_preferences': self.get_user_preferences(user_id)
        })

        # ë­í‚¹ ë° ë³‘í•©
        predictions = self.merge_and_rank(user_predictions, context_predictions)

        return predictions[:10]  # Top 10

    def generate_dynamic_email(self, user_id, email_type):
        """ë™ì  ì´ë©”ì¼ ìƒì„±"""
        user_profile = self.get_user_profile(user_id)

        # ì´ë©”ì¼ ë°œì†¡ ìµœì  ì‹œê°„ ì˜ˆì¸¡
        optimal_send_time = self.predict_optimal_send_time(user_id)

        # ì»¨í…ì¸  ìƒì„±
        if email_type == 'promotional':
            products = self.select_products_for_email(user_id, count=6)
            subject = self.generate_subject_line(user_profile, products)

            content = {
                'subject': subject,
                'header_image': self.select_header_image(user_profile),
                'greeting': self.personalize_greeting(user_profile),
                'products': products,
                'cta_text': self.optimize_cta(user_profile),
                'discount': self.calculate_personal_discount(user_id)
            }

        elif email_type == 'cart_abandonment':
            cart_items = self.get_abandoned_cart(user_id)

            content = {
                'subject': f"{user_profile['first_name']}ë‹˜, ì¥ë°”êµ¬ë‹ˆì— {len(cart_items)}ê°œ ìƒí’ˆì´ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”",
                'cart_items': cart_items,
                'incentive': self.generate_recovery_incentive(user_id),  # 10% í• ì¸ ë“±
                'urgency': self.create_urgency(cart_items)  # "2ê°œ ìƒí’ˆ ì¬ê³  ì–¼ë§ˆ ë‚¨ì§€ ì•ŠìŒ"
            }

        return {
            'content': content,
            'optimal_send_time': optimal_send_time,
            'ab_variant': self.assign_email_variant(user_id)
        }
```

**ë°ëª¨ ê°€ì¹˜:**
- ì‹¤ì‹œê°„ ê°œì¸í™”
- ML ê¸°ë°˜ ì»¨í…ì¸  ìƒì„±
- ë™ì  ì‚¬ìš©ì ê²½í—˜

---

## ğŸ“Š ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤

| ì„œë¹„ìŠ¤ | êµ¬í˜„ ë‚œì´ë„ | ë°ëª¨ ì„íŒ©íŠ¸ | í•™ìŠµ ê°€ì¹˜ | ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ | ì¶”ì²œë„ |
|--------|------------|-----------|---------|------------|--------|
| Visual Search | ì¤‘ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Dynamic Pricing | ì¤‘ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Real-time Inventory | ë‚® | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Sentiment Analysis | ì¤‘ | â­â­â­ | â­â­â­â­ | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Live Shopping | ë†’ìŒ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| Gamification | ì¤‘ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Social Shopping | ì¤‘ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| Customer Analytics | ì¤‘ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| NFT Collectibles | ë†’ìŒ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| Smart Mirror | ë†’ìŒ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| Collaborative Shopping | ì¤‘ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ |
| PWA Service | ë‚® | â­â­â­ | â­â­â­â­ | â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |
| Hyper-Personalization | ë†’ìŒ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ |

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

ê° ì„œë¹„ìŠ¤ë³„ë¡œ 30ë¶„ ì•ˆì— ê¸°ë³¸ ë²„ì „ì„ êµ¬í˜„í•  ìˆ˜ ìˆëŠ” ê°€ì´ë“œë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì–´ë–¤ ì„œë¹„ìŠ¤ë¥¼ ì‹¤ì œë¡œ êµ¬í˜„í•´ë³´ì‹œê² ìŠµë‹ˆê¹Œ?

1. **Visual Search** - ì´ë¯¸ì§€ ê¸°ë°˜ ì œí’ˆ ê²€ìƒ‰
2. **Dynamic Pricing** - AI ê°€ê²© ìµœì í™”
3. **Gamification** - í¬ì¸íŠ¸/ë°°ì§€ ì‹œìŠ¤í…œ
4. **Real-time Inventory** - ì‹¤ì‹œê°„ ì¬ê³  ë™ê¸°í™”
5. **PWA Service** - ì˜¤í”„ë¼ì¸ ëª¨ë“œ

ì„ íƒí•˜ì‹œë©´ ë°”ë¡œ êµ¬í˜„ ê°€ëŠ¥í•œ ì½”ë“œì™€ í•¨ê»˜ í”„ë¡œì íŠ¸ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤!
