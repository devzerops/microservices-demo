# Comprehensive Testing Suite

This directory contains a complete testing framework for the microservices demo project.

## ğŸ“ Directory Structure

```
tests/
â”œâ”€â”€ integration/          # Integration tests (service-to-service)
â”œâ”€â”€ contract/            # Contract tests with Pact
â”œâ”€â”€ performance/         # Performance and load tests with k6
â””â”€â”€ README.md           # This file
```

## ğŸ¯ Test Types

### 1. Integration Tests (`integration/`)

Tests that verify multiple services working together.

**Technologies:** Python, pytest, gRPC, Docker Compose

**What it tests:**
- Complete business workflows (browse â†’ cart â†’ checkout)
- Service-to-service communication
- Data flow across services
- Health checks for all services
- Error handling and edge cases

**Quick start:**
```bash
cd tests/integration
./run_tests.sh
```

**Key features:**
- âœ… Isolated Docker environment
- âœ… Real service communication
- âœ… Automated setup and teardown
- âœ… Complete checkout flow testing

[ğŸ“– Full Integration Testing Guide â†’](integration/README.md)

---

### 2. Contract Testing (`contract/`)

Consumer-Driven Contract Testing with Pact.

**Technologies:** Pact, Python

**What it tests:**
- API contracts between services
- Consumer expectations vs Provider implementation
- API compatibility and versioning
- Breaking changes detection

**Quick start:**
```bash
cd tests/contract

# Run consumer tests (generates contracts)
pytest consumer/ -v

# Run provider tests (verifies contracts)
pytest provider/ -v
```

**Key features:**
- âœ… Independent service deployment
- âœ… Early breaking change detection
- âœ… Living API documentation
- âœ… Fast feedback loop

[ğŸ“– Full Contract Testing Guide â†’](contract/README.md)

---

### 3. Performance Testing (`performance/`)

Load, stress, and spike testing with k6.

**Technologies:** k6 (JavaScript)

**What it tests:**
- System performance under load
- Response time percentiles (p95, p99)
- Throughput and capacity limits
- System breaking points
- Auto-scaling behavior

**Test scenarios:**
1. **Load Test** - Baseline performance (16 min, 100 VUs)
2. **Spike Test** - Traffic spikes (10 min, up to 1000 VUs)
3. **Stress Test** - Find limits (21 min, up to 1000 VUs)
4. **Black Friday** - E-commerce peak (2 hours, 1000+ VUs)
5. **API Performance** - Backend benchmarking (5 min, 150 RPS)

**Quick start:**
```bash
cd tests/performance
./run_k6_tests.sh
```

**Key features:**
- âœ… Realistic user scenarios
- âœ… Custom metrics and thresholds
- âœ… Multiple test patterns
- âœ… Results visualization

[ğŸ“– Full Performance Testing Guide â†’](performance/README.md)

---

## ğŸš€ Quick Start Guide

### Prerequisites

**For Integration Tests:**
```bash
# Docker and Docker Compose
docker --version
docker-compose --version

# Python 3.11+
python --version
pip install pytest grpcio grpcio-health-checking
```

**For Contract Tests:**
```bash
pip install pytest pact-python
```

**For Performance Tests:**
```bash
# Install k6
# macOS
brew install k6

# Linux
sudo apt-get install k6

# Or see: https://k6.io/docs/getting-started/installation/
```

### Running All Tests

**Option 1: Run each test suite individually**

```bash
# Integration tests (30-40 minutes)
cd tests/integration
./run_tests.sh

# Contract tests (5 minutes)
cd tests/contract
pytest consumer/ -v
pytest provider/ -v

# Performance tests (choose scenario)
cd tests/performance
./run_k6_tests.sh
```

**Option 2: Automated CI/CD pipeline**

See `.github/workflows/` for CI/CD integration examples.

---

## ğŸ“Š Test Matrix

| Test Type | Duration | Complexity | Isolation | Feedback Speed |
|-----------|----------|------------|-----------|----------------|
| Unit Tests | Seconds | Low | High | Very Fast |
| Contract Tests | Minutes | Medium | High | Fast |
| Integration Tests | 30+ min | High | Medium | Medium |
| Performance Tests | Hours | High | Low | Slow |

---

## ğŸ“ Testing Strategy

### Pyramid Approach

```
         /\
        /  \  E2E/Performance (Few)
       /    \
      /------\
     / Integ  \ Integration Tests (Some)
    /----------\
   /  Contract  \ Contract Tests (More)
  /--------------\
 /   Unit Tests   \ Unit Tests (Many)
/------------------\
```

### When to Use Each Test Type

**Unit Tests** (See `src/*/test_*.py` and `src/*/test_*.go`)
- Testing individual functions
- Fast feedback during development
- High code coverage

**Contract Tests** (`tests/contract/`)
- Defining API contracts
- Preventing breaking changes
- Independent service deployment

**Integration Tests** (`tests/integration/`)
- Verifying service interactions
- Testing complete workflows
- Pre-deployment validation

**Performance Tests** (`tests/performance/`)
- Capacity planning
- Identifying bottlenecks
- SLA validation

---

## ğŸ”„ CI/CD Integration

### GitHub Actions Workflow

```yaml
name: Test Suite

on: [push, pull_request]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    # ... run unit tests

  contract-tests:
    runs-on: ubuntu-latest
    # ... run contract tests

  integration-tests:
    runs-on: ubuntu-latest
    needs: [unit-tests, contract-tests]
    # ... run integration tests

  performance-tests:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    # ... run performance tests (main branch only)
```

### Test Gates

**Pull Request Requirements:**
- âœ… All unit tests pass
- âœ… Contract tests pass
- âœ… Code coverage > 80%

**Pre-Deployment:**
- âœ… Integration tests pass
- âœ… Performance benchmarks met

**Post-Deployment:**
- âœ… Smoke tests pass
- âœ… Performance monitoring

---

## ğŸ“ˆ Metrics and Reporting

### Integration Tests

**Output:**
- Test results (pass/fail)
- Service logs
- Docker container status

**Example:**
```
test_complete_checkout_flow PASSED [100%]
âœ“ Integration tests passed!
```

### Contract Tests

**Output:**
- Pact files (JSON contracts)
- Verification results
- Contract diff

**Files generated:**
```
pacts/
â”œâ”€â”€ recommendationservice-productcatalogservice.json
â””â”€â”€ checkoutservice-paymentservice.json
```

### Performance Tests

**Metrics:**
- Request duration (avg, p95, p99)
- Throughput (requests/sec)
- Error rate
- Data transferred

**Output formats:**
- Console summary
- JSON results
- CSV export
- Cloud dashboards

**Example:**
```
âœ“ http_req_duration..........: avg=234ms p(95)=456ms
âœ“ http_req_failed............: 4.76%
  http_reqs..................: 10000 (10.4/s)
```

---

## ğŸ› Debugging Failed Tests

### Integration Tests

**Issue:** Services fail to start
```bash
# Check logs
docker-compose -f tests/integration/docker-compose.test.yml logs

# Check individual service
docker-compose -f tests/integration/docker-compose.test.yml logs productcatalogservice
```

**Issue:** Tests timeout
- Increase timeout in pytest: `pytest --timeout=120`
- Check service health: `docker-compose ps`

### Contract Tests

**Issue:** Contract verification fails
- Check provider is running on correct port
- Verify provider states are implemented
- Compare expected vs actual response structure

### Performance Tests

**Issue:** High error rates
- Reduce virtual users (VUs)
- Increase ramp-up duration
- Check service capacity

**Issue:** Slow response times
- Profile application code
- Check database performance
- Review resource allocation

---

## ğŸ† Best Practices

### General

1. **Test Isolation:** Each test should be independent
2. **Clean Data:** Clean up test data after each run
3. **Deterministic:** Tests should give consistent results
4. **Fast Feedback:** Optimize test execution time
5. **Meaningful Names:** Clear test names describing what is tested

### Integration Tests

```python
# Good
def test_complete_checkout_flow_creates_order():
    """Test that completing checkout creates an order with items"""
    # ...

# Bad
def test_checkout():
    # ...
```

### Contract Tests

```python
# Good - Test what consumer actually uses
.with_request('get', '/products')
.will_respond_with(200, body={'products': EachLike({...})})

# Bad - Testing too much
.will_respond_with(200, body={'products': [...], 'metadata': {...}, ...})
```

### Performance Tests

```javascript
// Good - Realistic user behavior
export default function() {
  browseProducts();
  sleep(Math.random() * 3 + 1);  // Random think time
  addToCart();
  sleep(2);
}

// Bad - Unrealistic hammering
export default function() {
  http.get('/');
  http.get('/product/1');
  http.get('/cart');
  // No sleep, no realistic patterns
}
```

---

## ğŸ“š Additional Resources

### Documentation
- [Integration Testing README](integration/README.md)
- [Contract Testing README](contract/README.md)
- [Performance Testing README](performance/README.md)
- [Testing Enhancements Proposal](../TESTING_ENHANCEMENTS_PROPOSAL.md)

### External Resources
- [Martin Fowler - Microservices Testing](https://martinfowler.com/articles/microservice-testing/)
- [Pact Documentation](https://docs.pact.io/)
- [k6 Documentation](https://k6.io/docs/)
- [Test Pyramid](https://martinfowler.com/articles/practical-test-pyramid.html)

### Tools
- [pytest](https://docs.pytest.org/) - Python testing framework
- [Pact](https://docs.pact.io/) - Contract testing
- [k6](https://k6.io/) - Performance testing
- [Docker Compose](https://docs.docker.com/compose/) - Service orchestration

---

## ğŸ¤ Contributing

### Adding New Tests

1. **Integration Tests:**
   - Add test functions to `tests/integration/test_service_integration.py`
   - Update `docker-compose.test.yml` if new services needed

2. **Contract Tests:**
   - Consumer tests in `tests/contract/consumer/`
   - Provider tests in `tests/contract/provider/`

3. **Performance Tests:**
   - Add k6 scripts to `tests/performance/`
   - Update `run_k6_tests.sh` if needed

### Test Review Checklist

- [ ] Tests are independent and isolated
- [ ] Tests have clear, descriptive names
- [ ] Tests clean up after themselves
- [ ] Tests are documented
- [ ] Tests run in CI/CD pipeline
- [ ] Tests have appropriate timeouts
- [ ] Tests handle errors gracefully

---

## ğŸ¯ Test Coverage Goals

| Service | Unit | Integration | Contract | Performance |
|---------|------|-------------|----------|-------------|
| emailservice | âœ… 80% | âœ… | â¬œ | â¬œ |
| recommendationservice | âœ… 75% | âœ… | âœ… | âœ… |
| checkoutservice | âœ… 70% | âœ… | âœ… | âœ… |
| shippingservice | âœ… 85% | âœ… | â¬œ | âœ… |
| productcatalogservice | âœ… 80% | âœ… | âœ… | âœ… |
| cartservice | â¬œ 60% | âœ… | â¬œ | â¬œ |
| frontend | âœ… 65% | âœ… | â¬œ | âœ… |

**Legend:** âœ… Implemented | â¬œ Planned | Percentage = Code Coverage

---

## ğŸ“ Support

For questions or issues:
1. Check the relevant README in each test directory
2. Review [TESTING_ENHANCEMENTS_PROPOSAL.md](../TESTING_ENHANCEMENTS_PROPOSAL.md)
3. Open an issue in the repository

---

**Happy Testing! ğŸ‰**
